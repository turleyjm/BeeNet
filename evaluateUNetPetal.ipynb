{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/turleyjm/miniconda3/envs/BeeNet/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for model evaluation\n",
    "from cgitb import reset\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import skimage as sm\n",
    "import skimage.io\n",
    "from matplotlib import pyplot as plt\n",
    "import tifffile\n",
    "import timm\n",
    "from fastai.vision.all import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set evaluation hyperparameters and paths\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 401\n",
    "IMAGE_WIDTH = 401\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = True\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Creating directory. \" + directory)\n",
    "\n",
    "\n",
    "# Custom dataset class for loading electric field images without masks\n",
    "class VidDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "#         print(img_path)\n",
    "        image = sm.io.imread(img_path).astype(np.float32)\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        images = torch.tensor(image/2**16).float()\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image[0], image0=image[1], image1=image[2])\n",
    "            images[0] = transformed[\"image\"]\n",
    "            images[1] = transformed[\"image0\"]\n",
    "            images[2] = transformed[\"image1\"]\n",
    "\n",
    "            # save_transform(image, mask0, transformed)\n",
    "\n",
    "        return images\n",
    "\n",
    "\n",
    "# Load model checkpoint\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "# Create data loader for test images\n",
    "def get_loaders(\n",
    "    filename_dir,\n",
    "    batch_size,\n",
    "    filename_transform,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    "):\n",
    "    filename_ds = VidDataset(\n",
    "        image_dir=filename_dir,\n",
    "        transform=filename_transform\n",
    "    )\n",
    "\n",
    "    filename_loader = DataLoader(\n",
    "        filename_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return filename_loader\n",
    "\n",
    "\n",
    "# Generate predictions on test set and save as images\n",
    "def make_predictions(loader, model, folder=\"dat/train/input\", device=\"cuda\"):\n",
    "    model.eval()\n",
    "    loop = tqdm(loader)\n",
    "    with torch.no_grad():\n",
    "        p\n",
    "        for batch_idx, (x, pred_name) in enumerate(loop):\n",
    "            x = x.to(device)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            preds = np.asarray(preds*256, \"uint8\")\n",
    "            for i in range(preds.shape[0]):\n",
    "                tifffile.imwrite(\n",
    "                    f\"dat_output/{pred_name[i]}_pred.tif\", preds[i])\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# Main evaluation function\n",
    "def main():\n",
    "    target3 = {'image0': 'image', 'image1': 'image', 'image2': 'image', 'mask': 'mask'}\n",
    "    # Normalization transform for test images\n",
    "    filename_transform = A.Compose(\n",
    "        [\n",
    "            A.Normalize(\n",
    "                mean=0,\n",
    "                std=1,\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        additional_targets=target3,\n",
    "    )\n",
    "\n",
    "    # Load pretrained ResNet101 and build U-Net model\n",
    "    resnet = timm.create_model(\"resnet101\")\n",
    "\n",
    "    m = resnet\n",
    "    m = nn.Sequential(*list(m.children())[:-2])\n",
    "    model = DynamicUnet(m, 1, (401, 401), norm_type=None).to(DEVICE)\n",
    "\n",
    "    # Load trained model weights\n",
    "    load_checkpoint(torch.load(\"models/UNetPetal.pth.tar\"), model)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    print(\"predicting images\")\n",
    "\n",
    "    # Create output directory for predictions\n",
    "    createFolder(f\"dat_output\")\n",
    "    FILENAME_IMG_DIR = f\"dat/testing/input/\"\n",
    "    filename_loader = get_loaders(\n",
    "        FILENAME_IMG_DIR,\n",
    "        BATCH_SIZE,\n",
    "        filename_transform,  # train_transform\n",
    "        NUM_WORKERS,\n",
    "        PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "    # Generate and save predictions\n",
    "    make_predictions(filename_loader, model, folder=\"dat/testing/input/\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BeeNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
